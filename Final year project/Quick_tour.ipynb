{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick tour with QM9 [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Teoroo-CMC/PiNN/blob/TF2/docs/notebooks/Quick_tour.ipynb)\n",
    "\n",
    "This notebook showcases a simple example of training a neural network potential on the QM9 dataset with PiNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import os, warnings\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from ase.collections import g2\n",
    "from pinn.io import load_qm9, sparse_batch\n",
    "from pinn import get_model, get_calc\n",
    "# CPU is used for documentation generation, feel free to use your GPU!\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' \n",
    "# We heavily use indexed slices to do sparse summations,\n",
    "# which causes tensorflow to complain, \n",
    "# we believe it's safe to ignore this warning.\n",
    "index_warning = 'Converting sparse IndexedSlices'\n",
    "warnings.filterwarnings('ignore', index_warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the dataset\n",
    "\n",
    "PiNN adapts TensorFlow's dataset API to handle different datasets.\n",
    "\n",
    "For this and the following notebooks the QM9 dataset (https://doi.org/10.6084/m9.figshare.978904) is used.  \n",
    "To follow the notebooks, download the dataset and change the directory accordingly.\n",
    "\n",
    "The dataset will be automatically split into subsets according to the split_ratio.  \n",
    "Note that to use the dataset with the estimator, the datasets should be a function, instead of a dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob('/Users/miguelnavaharris/Project/QM9/*.xyz')\n",
    "dataset = lambda: load_qm9(filelist, splits={'train':8, 'test':2}) #lambda is being used here to assign execution of load_qm9 to a variable dataset\n",
    "train = lambda: dataset()['train'].repeat().shuffle(1000).apply(sparse_batch(256))\n",
    "test = lambda: dataset()['test'].repeat().apply(sparse_batch(256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'FlatMapDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/miguelnavaharris/PiNN/docs/notebooks/Quick_tour.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/miguelnavaharris/PiNN/docs/notebooks/Quick_tour.ipynb#ch0000016?line=0'>1</a>\u001b[0m dataset()[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'FlatMapDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "dataset()['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_qm9(filelist, splits={'train':8, 'test':2}) \n",
    "#returns a dictionary, as does dataset() \n",
    "#since load_qm9 is assigned to a lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <lambda> at 0x104e91670>\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "<class 'dict'>\n",
      "Here is the dataset dictionary: {'train': <FlatMapDataset shapes: {elems: (None,), coord: (None, 3), e_data: ()}, types: {elems: tf.int32, coord: tf.float32, e_data: tf.float32}>, 'test': <FlatMapDataset shapes: {elems: (None,), coord: (None, 3), e_data: ()}, types: {elems: tf.int32, coord: tf.float32, e_data: tf.float32}>}\n",
      "The train set is: <FlatMapDataset shapes: {elems: (None,), coord: (None, 3), e_data: ()}, types: {elems: tf.int32, coord: tf.float32, e_data: tf.float32}>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 18:31:22.222449: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-21 18:31:22.222579: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(type(dataset()))\n",
    "print('Here is the dataset dictionary:', dataset())\n",
    "print('The train set is:', dataset()['train'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model\n",
    "In PiNN, models are defined at two levels: models and networks. \n",
    "\n",
    "- A model (model_fn) defines the target, loss and training detail.\n",
    "- A network defines the structure of the neural network.\n",
    "\n",
    "In this example, we will use the potential model, and the PiNet network.\n",
    "The configuration of a model is stored in a nested dictionary as shown below.\n",
    "Available options of the network and model can be found in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/Users/miguelnavaharris/Project/miguelmodels/Quick_tour_unedited', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "params = {'model_dir': '/Users/miguelnavaharris/Project/miguelmodels/Quick_tour_unedited',\n",
    "          'network': {\n",
    "              'name': 'PiNet',\n",
    "              'params': {\n",
    "                  'depth': 4,\n",
    "                  'rc':4.0,\n",
    "                  'atom_types':[1,6,7,8,9]\n",
    "              },\n",
    "          },\n",
    "          'model': {\n",
    "              'name': 'potential_model',\n",
    "              'params': {\n",
    "                  'learning_rate': 1e-3\n",
    "              }\n",
    "          }\n",
    "}\n",
    "model = get_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x1041ee4f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the training process\n",
    "The defined model is indeed a [tf.Estimator](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator) object, thus, the training can be easily controlled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(input_fn=train, max_steps=1000)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=test, steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /Users/miguelnavaharris/miniforge3/envs/pinn2/lib/python3.9/site-packages/tensorflow/python/training/training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/miguelnavaharris/miniforge3/envs/pinn2/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "12112 trainable vaiabless, training with float32 precision.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 14:03:03.567137: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-06 14:03:03.567370: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-04-06 14:03:03.603951: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-06 14:03:03.605365: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:03:03.756899: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 14:03:03.801525: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:03:03.809464: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:03:03.852765: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /Users/miguelnavaharris/Project/miguelmodels/Quick_tour_unedited/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 14:03:04.300044: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:03:04.436743: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:03:04.451495: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-06 14:03:04.457516: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:03:04.726420: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-06 14:03:04.726445: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 147102.08, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 14:03:05.773748: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.28618\n",
      "INFO:tensorflow:loss = 1492.9783, step = 100 (43.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.76723\n",
      "INFO:tensorflow:loss = 661.8176, step = 200 (56.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43248\n",
      "INFO:tensorflow:loss = 452.7468, step = 300 (69.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44583\n",
      "INFO:tensorflow:loss = 698.9434, step = 400 (69.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.29325\n",
      "INFO:tensorflow:loss = 243.93387, step = 500 (77.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09404\n",
      "INFO:tensorflow:loss = 400.42883, step = 600 (91.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07204\n",
      "INFO:tensorflow:loss = 273.13846, step = 700 (93.287 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 798...\n",
      "INFO:tensorflow:Saving checkpoints for 798 into /Users/miguelnavaharris/Project/miguelmodels/Quick_tour_unedited/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 798...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-04-06T14:13:05\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /Users/miguelnavaharris/Project/miguelmodels/Quick_tour_unedited/model.ckpt-798\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 14:13:05.844887: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-06 14:13:05.844910: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-04-06 14:13:05.925275: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:13:05.974401: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:13:05.997161: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:13:06.005203: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:13:06.025824: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:13:06.071349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 14:13:52.660823: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 47.16914s\n",
      "INFO:tensorflow:Finished evaluation at 2022-04-06-14:13:52\n",
      "INFO:tensorflow:Saving dict for global step 798: METRICS/E_LOSS = 211.04352, METRICS/E_MAE = 11.107614, METRICS/E_RMSE = 14.527341, global_step = 798, loss = 211.04352\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 798: /Users/miguelnavaharris/Project/miguelmodels/Quick_tour_unedited/model.ckpt-798\n",
      "INFO:tensorflow:global_step/sec: 0.666697\n",
      "INFO:tensorflow:loss = 207.74348, step = 800 (149.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.939646\n",
      "INFO:tensorflow:loss = 217.91988, step = 900 (106.425 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /Users/miguelnavaharris/Project/miguelmodels/Quick_tour_unedited/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-04-06T14:17:30\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /Users/miguelnavaharris/Project/miguelmodels/Quick_tour_unedited/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 14:17:30.613002: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-06 14:17:30.613029: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-04-06 14:17:30.629614: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:17:30.654880: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:17:30.672340: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:17:30.679442: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:17:30.698661: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:17:30.712075: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 14:18:22.326088: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 52.09381s\n",
      "INFO:tensorflow:Finished evaluation at 2022-04-06-14:18:22\n",
      "INFO:tensorflow:Saving dict for global step 1000: METRICS/E_LOSS = 264.58563, METRICS/E_MAE = 14.023312, METRICS/E_RMSE = 16.266088, global_step = 1000, loss = 264.58563\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /Users/miguelnavaharris/Project/miguelmodels/Quick_tour_unedited/model.ckpt-1000\n",
      "INFO:tensorflow:Loss for final step: 145.12006.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'METRICS/E_LOSS': 264.58563,\n",
       "  'METRICS/E_MAE': 14.023312,\n",
       "  'METRICS/E_RMSE': 16.266088,\n",
       "  'loss': 264.58563,\n",
       "  'global_step': 1000},\n",
       " [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.estimator.train_and_evaluate(model, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model\n",
    "\n",
    "The trained model can be used as an ASE calculator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/PiNet_QM92', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Could not find trained model in model_dir: /tmp/PiNet_QM92, running initialization to predict.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 14:23:01.524440: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-06 14:23:01.524458: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-04-06 14:23:01.545157: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 14:23:01.945906: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:23:01.965764: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:23:01.971245: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:23:01.991322: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 14:23:02.003485: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.0000000e+00,  8.9406967e-08, -2.5586405e+00],\n",
       "        [-0.0000000e+00,  2.8312206e-07,  2.5586410e+00],\n",
       "        [-0.0000000e+00, -2.2626185e+00, -1.8785739e+00],\n",
       "        [-0.0000000e+00,  2.2626183e+00, -1.8785739e+00],\n",
       "        [-0.0000000e+00, -2.2626183e+00,  1.8785739e+00],\n",
       "        [-0.0000000e+00,  2.2626181e+00,  1.8785737e+00]], dtype=float32),\n",
       " -9.658690452575684)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ase.collections import g2\n",
    "from pinn import get_calc\n",
    "params = {'model_dir': '/tmp/PiNet_QM92',\n",
    "          'network': {\n",
    "              'name': 'PiNet',\n",
    "              'params': {\n",
    "                  'depth': 4,\n",
    "                  'rc':4.0,\n",
    "                  'atom_types':[1,6,7,8,9]\n",
    "              },\n",
    "          },\n",
    "          'model': {\n",
    "              'name': 'potential_model',\n",
    "              'params': {\n",
    "                  'learning_rate': 1e-3\n",
    "              }\n",
    "          }\n",
    "}\n",
    "\n",
    "calc = get_calc(params)\n",
    "calc.properties = ['energy']\n",
    "atoms = g2['C2H4']\n",
    "atoms.set_calculator(calc)\n",
    "atoms.get_forces(), atoms.get_potential_energy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You have trained your first PiNN model, though the accuracy is not so satisfying\n",
    "(RMSE=21 Hartree!). Also, the training speed is slow as it's limited by the IO and \n",
    "pre-processing of data.  \n",
    "\n",
    "We will show in following notebooks that:\n",
    "\n",
    "- Proper scaling of the energy will improve the accuracy of the model.\n",
    "- The training speed can be enhanced by caching and pre-processing the data."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4025a0c18342a57b4a17c482f921a5b0f0c41971fda061095662d1f6a4a25c7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
