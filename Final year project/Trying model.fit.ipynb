{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pinn import get_network\n",
    "from pinn.utils import connect_dist_grad\n",
    "from glob import glob\n",
    "from ase.collections import g2\n",
    "from pinn.io import load_qm9, sparse_batch\n",
    "from pinn.optimizers import get\n",
    "import time\n",
    "import psutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices()\n",
    "tf.config.set_visible_devices(physical_devices[0], 'CPU')\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob('/Users/miguelnavaharris/Project/QM9/*.xyz')\n",
    "dataset = load_qm9(filelist, splits={'train':8, 'test':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_traintest_sets(batch_size):\n",
    "    train_set = dataset['train'].shuffle(20000).apply(sparse_batch(batch_size))\n",
    "    test_set = dataset['test'].apply(sparse_batch(batch_size))\n",
    "    return (train_set, test_set, batch_size)\n",
    "\n",
    "def get_dataset_size(dataset):\n",
    "    return len(list(dataset))\n",
    "    \n",
    "def preprocess_traintest_sets(train_set, test_set):\n",
    "    for batch in train_set:\n",
    "        batch = network.preprocess(batch)\n",
    "        connect_dist_grad(batch)\n",
    "    for batch in test_set:\n",
    "        batch = network.preprocess(batch)\n",
    "        connect_dist_grad(batch)\n",
    "\n",
    "def get_compiled_network():\n",
    "    optimizer = get(params['optimizer'])\n",
    "    loss_fn = tf.keras.losses.mse\n",
    "    network.compile(optimizer=optimizer, loss=loss_fn, metrics=[tf.keras.metrics.MeanAbsoluteError(), tf.keras.metrics.MeanSquaredError()]) #setting run_eagerly=True was a possible fix for memory leak\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# from tensorflow.keras import backend as k\n",
    "# from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "# class ClearMemory(Callback):\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         gc.collect()\n",
    "#         k.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculesPerSec(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, no_batches, batch_size, logdir):\n",
    "        self.no_batches = no_batches\n",
    "        self.batch_size = batch_size\n",
    "        self.tb_callback = tb_callback\n",
    "        self.no_molecules = self.no_batches * self.batch_size\n",
    "        self.batch_number = 0\n",
    "        self.global_step = 0\n",
    "        self.writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.batch_time_start = time.time()\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.batch_number += 1\n",
    "        batch_time = time.time() - self.batch_time_start\n",
    "        molecules_per_second = self.batch_size / batch_time\n",
    "        ram_usage_mb, swap_usage_mb = self.get_ram_and_swap_usage()\n",
    "\n",
    "        with self.writer.as_default():\n",
    "            tf.summary.scalar('batch_moleculespersec', molecules_per_second, step=self.global_step)\n",
    "            tf.summary.scalar('batch_ram_usage_mb', ram_usage_mb, step=self.global_step)\n",
    "            tf.summary.scalar('batch_swap_usage_mb', swap_usage_mb, step=self.global_step)\n",
    "\n",
    "        self.global_step += 1\n",
    "\n",
    "    def get_ram_and_swap_usage(self):\n",
    "        mem_info = psutil.virtual_memory()\n",
    "        ram_usage_mb = mem_info.used / (1024 * 1024)\n",
    "\n",
    "        swap_info = psutil.swap_memory()\n",
    "        swap_usage_mb = swap_info.used / (1024 * 1024)\n",
    "\n",
    "        return ram_usage_mb, swap_usage_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'optimizer': {'class_name': 'Adam', 'config': {'learning_rate': {'class_name': 'ExponentialDecay', 'config': {'initial_learning_rate': 0.0003, 'decay_steps': 10000, 'decay_rate': 0.994}}, 'clipnorm': 0.01}}, 'network': {'name': 'PiNet', 'params': {'depth': 4, 'rc': 4.0, 'atom_types': [1, 6, 7, 8, 9]}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = get_network(params['network'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, batch_size = get_traintest_sets(batch_size=256)\n",
    "preprocess_traintest_sets(train_set, test_set)\n",
    "no_batches = get_dataset_size(train_set)\n",
    "test_set_size = get_dataset_size(test_set)\n",
    "steps_per_epoch = 107108 / batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 01:04:12.842101: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2023-03-31 01:04:12.842223: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2023-03-31 01:04:12.844615: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "network = get_compiled_network()\n",
    "logdir = '/Users/miguelnavaharris/New_Benchmarks/PiNet_TF2/' +  str(batch_size)\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(logdir, update_freq=1)\n",
    "moleculespersec_callback = MoleculesPerSec(no_batches, batch_size, logdir)\n",
    "callbacks=[tb_callback, moleculespersec_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape mismatch in elems: Tensor(\"pi_net_1/preprocess_layer_1/cond/Shape:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelnavaharris/miniforge3/envs/pinn/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"concat_1:0\", shape=(None,), dtype=int32), values=Tensor(\"concat:0\", shape=(None, 16), dtype=float32), dense_shape=Tensor(\"gradient_tape/pi_net_1/gc_block_7/pi_layer_7/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/miguelnavaharris/miniforge3/envs/pinn/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"concat_3:0\", shape=(None,), dtype=int32), values=Tensor(\"concat_2:0\", shape=(None, 16), dtype=float32), dense_shape=Tensor(\"gradient_tape/pi_net_1/gc_block_6/pi_layer_6/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/miguelnavaharris/miniforge3/envs/pinn/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"concat_5:0\", shape=(None,), dtype=int32), values=Tensor(\"concat_4:0\", shape=(None, 16), dtype=float32), dense_shape=Tensor(\"gradient_tape/pi_net_1/gc_block_5/pi_layer_5/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape mismatch in elems: Tensor(\"pi_net_1/preprocess_layer_1/cond/Shape:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 01:04:21.652579: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/418 [..............................] - ETA: 57:08 - loss: 209798.8125 - mean_absolute_error: 456.8308 - mean_squared_error: 209798.8125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 01:04:28.889059: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2023-03-31 01:04:28.889070: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/418 [..............................] - ETA: 8:13 - loss: 203106.3594 - mean_absolute_error: 448.9636 - mean_squared_error: 203106.3594 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 01:04:30.134519: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2023-03-31 01:04:30.143956: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2023-03-31 01:04:30.151980: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /Users/miguelnavaharris/New_Benchmarks/PiNet_TF2/256/train/plugins/profile/2023_03_31_01_04_30\n",
      "2023-03-31 01:04:30.157062: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /Users/miguelnavaharris/New_Benchmarks/PiNet_TF2/256/train/plugins/profile/2023_03_31_01_04_30/ch-gouldmac7.ch.ic.ac.uk.trace.json.gz\n",
      "2023-03-31 01:04:30.164981: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /Users/miguelnavaharris/New_Benchmarks/PiNet_TF2/256/train/plugins/profile/2023_03_31_01_04_30\n",
      "2023-03-31 01:04:30.165281: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /Users/miguelnavaharris/New_Benchmarks/PiNet_TF2/256/train/plugins/profile/2023_03_31_01_04_30/ch-gouldmac7.ch.ic.ac.uk.memory_profile.json.gz\n",
      "2023-03-31 01:04:30.165957: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /Users/miguelnavaharris/New_Benchmarks/PiNet_TF2/256/train/plugins/profile/2023_03_31_01_04_30Dumped tool data for xplane.pb to /Users/miguelnavaharris/New_Benchmarks/PiNet_TF2/256/train/plugins/profile/2023_03_31_01_04_30/ch-gouldmac7.ch.ic.ac.uk.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /Users/miguelnavaharris/New_Benchmarks/PiNet_TF2/256/train/plugins/profile/2023_03_31_01_04_30/ch-gouldmac7.ch.ic.ac.uk.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /Users/miguelnavaharris/New_Benchmarks/PiNet_TF2/256/train/plugins/profile/2023_03_31_01_04_30/ch-gouldmac7.ch.ic.ac.uk.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /Users/miguelnavaharris/New_Benchmarks/PiNet_TF2/256/train/plugins/profile/2023_03_31_01_04_30/ch-gouldmac7.ch.ic.ac.uk.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /Users/miguelnavaharris/New_Benchmarks/PiNet_TF2/256/train/plugins/profile/2023_03_31_01_04_30/ch-gouldmac7.ch.ic.ac.uk.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/418 [====================>.........] - ETA: 2:55 - loss: 9606.2715 - mean_absolute_error: 51.8763 - mean_squared_error: 9606.2715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _EagerDefinedFunctionDeleter.__del__ at 0x13f77d670>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/miguelnavaharris/miniforge3/envs/pinn/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 406, in __del__\n",
      "  File \"/Users/miguelnavaharris/miniforge3/envs/pinn/lib/python3.9/site-packages/tensorflow/python/eager/context.py\", line 2443, in remove_function\n",
      "  File \"/Users/miguelnavaharris/miniforge3/envs/pinn/lib/python3.9/site-packages/tensorflow/python/eager/context.py\", line 1208, in remove_function\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "network.fit(train_set, epochs=1, steps_per_epoch=steps_per_epoch, validation_data=test_set, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASE Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generator(molecule):\n",
    "        data = {'coord': molecule.positions,\n",
    "                'ind_1': np.zeros([len(molecule), 1]),\n",
    "                'elems': molecule.numbers}\n",
    "        yield data\n",
    "\n",
    "def predict_energy(molecule):\n",
    "        '''Takes an ASE Atoms object and outputs PiNet's energy prediction'''\n",
    "        dtype=tf.float32\n",
    "        dtypes = {'coord': dtype, 'elems': tf.int32, 'ind_1': tf.int32}\n",
    "        shapes = {'coord': [None, 3], 'elems': [None], 'ind_1': [None, 1]}\n",
    "\n",
    "        pred_dataset = tf.data.Dataset.from_generator(lambda:_generator(molecule), dtypes, shapes)\n",
    "\n",
    "        for molecule in pred_dataset:\n",
    "                molecule = network.preprocess(molecule)\n",
    "                pred = network(molecule, training=False)\n",
    "                ind = molecule['ind_1']\n",
    "                nbatch = tf.reduce_max(ind)+1\n",
    "                energy_prediction = tf.math.unsorted_segment_sum(pred, ind[:, 0], nbatch)\n",
    "                energy_prediction_numpy = energy_prediction.numpy()[0]\n",
    "        return energy_prediction_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coord': array([[ 0.      ,  0.      ,  0.      ],\n",
       "        [ 0.629118,  0.629118,  0.629118],\n",
       "        [-0.629118, -0.629118,  0.629118],\n",
       "        [ 0.629118, -0.629118, -0.629118],\n",
       "        [-0.629118,  0.629118, -0.629118]]),\n",
       " 'ind_1': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'elems': array([6, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(_generator(g2['CH4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-39.6263"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_energy(g2['CH4'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4025a0c18342a57b4a17c482f921a5b0f0c41971fda061095662d1f6a4a25c7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('pinn2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
