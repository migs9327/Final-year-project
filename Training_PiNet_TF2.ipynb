{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pinn import get_network\n",
    "from pinn.utils import connect_dist_grad\n",
    "from glob import glob\n",
    "from ase.collections import g2\n",
    "from pinn.io import load_qm9, sparse_batch\n",
    "from pinn.optimizers import get\n",
    "import psutil\n",
    "import os\n",
    "import time\n",
    "from pinn.layers import PolynomialBasis, GaussianBasis, ANNOutput\n",
    "from pinn.networks.pinet import OutLayer, GCBlock, ResUpdate, PreprocessLayer\n",
    "from pinn.utils import atomic_dress, get_atomic_dress\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "from mendeleev import element\n",
    "import gc\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to disable GPU\n",
    "# physical_devices = tf.config.list_physical_devices()\n",
    "# tf.config.set_visible_devices(physical_devices[0], 'CPU')\n",
    "# tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 13:12:48.613113: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-04-30 13:12:48.613211: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-04-30 13:12:48.630701: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-04-30 13:12:48.630806: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "filelist = glob('/Users/miguelnavaharris/Project/QM9/*.xyz')\n",
    "num_trainset_samples = 0.8 * len(filelist)\n",
    "num_testset_samples = 0.2 * len(filelist)\n",
    "dataset = load_qm9(filelist, splits={'train':8, 'test':2})\n",
    "dress, error = get_atomic_dress(dataset['train'],[1,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_traintest_sets(dataset,batch_size, buffer_size=20000):\n",
    "    train_set = dataset['train'].cache().shuffle(buffer_size).apply(sparse_batch(batch_size))\n",
    "    test_set = dataset['test'].cache().apply(sparse_batch(batch_size))\n",
    "    return (train_set, test_set, batch_size)\n",
    "\n",
    "def get_dataset_size(dataset):\n",
    "    return len(list(dataset))\n",
    "    \n",
    "def preprocess_traintest_sets(train_set, test_set):\n",
    "    for batch in train_set:\n",
    "        batch = network.preprocess(batch)\n",
    "        connect_dist_grad(batch)\n",
    "    for batch in test_set:\n",
    "        batch = network.preprocess(batch)\n",
    "        connect_dist_grad(batch)\n",
    "\n",
    "def get_compiled_network():\n",
    "    optimizer = get(params['optimizer'])\n",
    "    loss_fn = tf.keras.losses.mse\n",
    "    network.compile(optimizer=optimizer, loss=loss_fn, metrics=[tf.keras.metrics.MeanAbsoluteError(), tf.keras.metrics.MeanSquaredError()]) #setting run_eagerly=True was a possible fix for memory leak\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearMemory(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "        k.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PiNet(tf.keras.Model):\n",
    "    \"\"\"Keras model for the PiNet neural network\n",
    "\n",
    "    Args:\n",
    "        tensors: input data (nested tensor from dataset).\n",
    "        atom_types (list): elements for the one-hot embedding.\n",
    "        pp_nodes (list): number of nodes for pp layer.\n",
    "        pi_nodes (list): number of nodes for pi layer.\n",
    "        ii_nodes (list): number of nodes for ii layer.\n",
    "        en_nodes (list): number of nodes for en layer.\n",
    "        depth (int): number of interaction blocks.\n",
    "        rc (float): cutoff radius.\n",
    "        basis_type (string): type of basis function to use,\n",
    "            can be \"polynomial\" or \"gaussian\".\n",
    "        n_basis (int): number of basis functions to use.\n",
    "        gamma (float or array): width of gaussian function for gaussian basis.\n",
    "        center (float or array): center of gaussian function for gaussian basis.\n",
    "        cutoff_type (string): cutoff function to use with the basis.\n",
    "        act (string): activation function to use.\n",
    "        preprocess (bool): whether to return the preprocessed tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, atom_types=[1, 6, 7, 8, 9],  rc=4.0, cutoff_type='f1',\n",
    "                 basis_type='polynomial', n_basis=4, gamma=3.0, center=None,\n",
    "                 pp_nodes=[16, 16], pi_nodes=[16, 16], ii_nodes=[16, 16],\n",
    "                 out_nodes=[16, 16], out_units=1, out_pool=False,\n",
    "                 act='tanh', depth=4):\n",
    "\n",
    "        super(PiNet, self).__init__()\n",
    "\n",
    "        self.depth = depth\n",
    "        self.preprocess = PreprocessLayer(atom_types, rc)\n",
    "        self.activation = act\n",
    "\n",
    "        if basis_type == 'polynomial':\n",
    "            self.basis_fn = PolynomialBasis(cutoff_type, rc, n_basis)\n",
    "        elif basis_type == 'gaussian':\n",
    "            self.basis_fn = GaussianBasis(cutoff_type, rc, n_basis, gamma, center)\n",
    "\n",
    "        self.res_update = [ResUpdate() for i in range(depth)]\n",
    "        self.gc_blocks = [GCBlock([], pi_nodes, ii_nodes, activation=act)]\n",
    "        self.gc_blocks += [GCBlock(pp_nodes, pi_nodes, ii_nodes, activation=act)\n",
    "                           for i in range(depth-1)]\n",
    "        self.out_layers = [OutLayer(out_nodes, out_units) for i in range(depth)]\n",
    "        self.ann_output =  ANNOutput(out_pool)\n",
    "        \n",
    "    \n",
    "    def train_step(self, tensors):\n",
    "\n",
    "        e_data_original = tf.identity(tensors['e_data'])\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_transformed = self(tensors, training=True)\n",
    "\n",
    "            if params['params']['e_dress']:\n",
    "                dress = atomic_dress(tensors, params['params']['e_dress'], dtype=pred_transformed.dtype)\n",
    "                e_data_transformed = tensors['e_data'] - dress\n",
    "            else:\n",
    "                e_data_transformed = tensors['e_data']\n",
    "\n",
    "            # e_data_transformed *= params['params']['e_scale']\n",
    "            loss = self.compiled_loss(e_data_transformed, pred_transformed, regularization_losses=self.losses)\n",
    "\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Reverse the scaling and atomic dress for predictions and true atomic energies\n",
    "        pred_original = pred_transformed #/ params['params']['e_scale']\n",
    "        if params['params']['e_dress']:\n",
    "            pred_original += dress\n",
    "\n",
    "        # Compute the metrics on the original scale\n",
    "        self.compiled_metrics.update_state(e_data_original, pred_original)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, tensors):\n",
    "\n",
    "        pred_transformed = self(tensors, training=False)\n",
    "        e_data_original = tf.identity(tensors['e_data'])\n",
    "        if params['params']['e_dress']:\n",
    "            dress = atomic_dress(tensors, params['params']['e_dress'], dtype=pred_transformed.dtype)\n",
    "            e_data_transformed = tensors['e_data'] - dress\n",
    "        else:\n",
    "            e_data_transformed = tensors['e_data'] \n",
    "        # e_data_transformed *= params['params']['e_scale']\n",
    "        self.compiled_loss(e_data_transformed, pred_transformed, regularization_losses=self.losses)\n",
    "\n",
    "        # Reverse the scaling and atomic dress for predictions and true atomic energies\n",
    "        pred_original = pred_transformed #/ params['params']['e_scale']\n",
    "        if params['params']['e_dress']:\n",
    "            pred_original += dress\n",
    "\n",
    "        # Compute the metrics on the original scale\n",
    "        self.compiled_metrics.update_state(e_data_original, pred_original)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    \n",
    "\n",
    "    def call(self, tensors):\n",
    "        tensors = self.preprocess(tensors)\n",
    "        basis = self.basis_fn(tensors['dist'])[:, None, :]\n",
    "        output = 0.0\n",
    "        for i in range(self.depth):\n",
    "            prop = self.gc_blocks[i]([tensors['ind_2'], tensors['prop'], basis])\n",
    "            output = self.out_layers[i]([tensors['ind_1'], prop, output])\n",
    "            tensors['prop'] = self.res_update[i]([tensors['prop'], prop])\n",
    "\n",
    "        output = self.ann_output([tensors['ind_1'], output])\n",
    "        ind = tensors['ind_1']\n",
    "        nbatch = tf.reduce_max(ind)+1\n",
    "        output_by_batch = tf.math.unsorted_segment_sum(output, ind[:, 0], nbatch)\n",
    "        return output_by_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculesPerSec(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, no_batches, batch_size, logdir):\n",
    "        self.no_batches = no_batches\n",
    "        self.batch_size = batch_size\n",
    "        self.no_molecules = self.no_batches * self.batch_size\n",
    "        self.batch_number = 0\n",
    "        self.writer = tf.summary.create_file_writer(logdir)  # Use logdir for creating a writer\n",
    "        self.process = psutil.Process(os.getpid())  # Get the current process\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.batch_time_start = time.time()\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.batch_number += 1\n",
    "        batch_time = time.time() - self.batch_time_start\n",
    "        molecules_per_second = self.batch_size / batch_time\n",
    "        ram_usage_mb, swap_usage_mb = self.get_ram_and_swap_usage()\n",
    "\n",
    "        step = self.model.optimizer.iterations.numpy()  # Get the current step from the model's optimizer\n",
    "\n",
    "        with self.writer.as_default():\n",
    "            tf.summary.scalar('batch_moleculespersec', molecules_per_second, step=step)\n",
    "            tf.summary.scalar('batch_ram_usage_mb', ram_usage_mb, step=step)\n",
    "            tf.summary.scalar('batch_swap_usage_mb', swap_usage_mb, step=step)\n",
    "\n",
    "    def get_ram_and_swap_usage(self):\n",
    "        memory_info = self.process.memory_info()  # Get memory info for the current process\n",
    "        ram_usage_mb = memory_info.rss / (1024 * 1024)\n",
    "\n",
    "        swap_info = psutil.swap_memory()\n",
    "        swap_usage_mb = swap_info.used / (1024 * 1024)\n",
    "\n",
    "        return ram_usage_mb, swap_usage_mb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'optimizer': {\n",
    "        'class_name': 'Adam',\n",
    "        'config': {\n",
    "            'learning_rate': {\n",
    "                'class_name': 'ExponentialDecay',\n",
    "                'config': {\n",
    "                    'initial_learning_rate': 1e-3,\n",
    "                    'decay_steps': 10000, \n",
    "                    'decay_rate': 0.994}}, \n",
    "                    'clipnorm': 0.01}},    \n",
    "            'params': {\n",
    "                  'learning_rate': 1e-3, # Relatively large learning rate\n",
    "                  'e_scale': 627.5, # Here we scale the model to kcal/mol\n",
    "                  'e_dress': dress\n",
    "              }\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = PiNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, batch_size = get_traintest_sets(dataset, batch_size)\n",
    "preprocess_traintest_sets(train_set, test_set)\n",
    "no_batches = get_dataset_size(train_set)\n",
    "steps_per_epoch = num_trainset_samples // batch_size\n",
    "validation_steps = num_testset_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 13:14:00.706035: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2023-04-30 13:14:00.706048: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2023-04-30 13:14:00.706475: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "network = get_compiled_network()\n",
    "logdir = '/Users/miguelnavaharris/New_Benchmarks/Prediction_accuracy/M1/Rescaled_correctly/PiNet_20_epochs_256_dressnoscale/' +  str(batch_size)\n",
    "# early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2, mode='min', restore_best_weights=True)\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(logdir, update_freq=1)\n",
    "moleculespersec_callback = MoleculesPerSec(no_batches, batch_size, logdir)\n",
    "callbacks=[tb_callback, moleculespersec_callback]# , early_stopping_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Shape mismatch in elems: Tensor(\"pi_net/preprocess_layer/cond/Shape:0\", shape=(1,), dtype=int32)\n",
      "WARNING:tensorflow:From /Users/miguelnavaharris/miniforge3/envs/pinn/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelnavaharris/miniforge3/envs/pinn/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"concat_1:0\", shape=(None,), dtype=int32), values=Tensor(\"concat:0\", shape=(None, 16), dtype=float32), dense_shape=Tensor(\"gradient_tape/pi_net/gc_block_3/pi_layer_3/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/miguelnavaharris/miniforge3/envs/pinn/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"concat_3:0\", shape=(None,), dtype=int32), values=Tensor(\"concat_2:0\", shape=(None, 16), dtype=float32), dense_shape=Tensor(\"gradient_tape/pi_net/gc_block_2/pi_layer_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/miguelnavaharris/miniforge3/envs/pinn/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"concat_5:0\", shape=(None,), dtype=int32), values=Tensor(\"concat_4:0\", shape=(None, 16), dtype=float32), dense_shape=Tensor(\"gradient_tape/pi_net/gc_block_1/pi_layer_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape mismatch in elems: Tensor(\"pi_net/preprocess_layer/cond/Shape:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 13:14:03.614607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 3s 3s/step - loss: 6130.5352 - mean_absolute_error: 75.6426 - mean_squared_error: 6130.5352"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 13:14:05.301119: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2023-04-30 13:14:05.301132: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown - 4s 524ms/step - loss: 3271.3008 - mean_absolute_error: 47.1252 - mean_squared_error: 3271.3008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 13:14:05.768157: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2023-04-30 13:14:05.774239: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2023-04-30 13:14:05.780269: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /Users/miguelnavaharris/New_Benchmarks/Prediction_accuracy/M1/Rescaled_correctly/PiNet_20_epochs_256_dressnoscale/256/train/plugins/profile/2023_04_30_13_14_05\n",
      "2023-04-30 13:14:05.784365: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /Users/miguelnavaharris/New_Benchmarks/Prediction_accuracy/M1/Rescaled_correctly/PiNet_20_epochs_256_dressnoscale/256/train/plugins/profile/2023_04_30_13_14_05/ch-gouldmac7.ch.ic.ac.uk.trace.json.gz\n",
      "2023-04-30 13:14:05.789339: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /Users/miguelnavaharris/New_Benchmarks/Prediction_accuracy/M1/Rescaled_correctly/PiNet_20_epochs_256_dressnoscale/256/train/plugins/profile/2023_04_30_13_14_05\n",
      "2023-04-30 13:14:05.789770: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /Users/miguelnavaharris/New_Benchmarks/Prediction_accuracy/M1/Rescaled_correctly/PiNet_20_epochs_256_dressnoscale/256/train/plugins/profile/2023_04_30_13_14_05/ch-gouldmac7.ch.ic.ac.uk.memory_profile.json.gz\n",
      "2023-04-30 13:14:05.790375: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /Users/miguelnavaharris/New_Benchmarks/Prediction_accuracy/M1/Rescaled_correctly/PiNet_20_epochs_256_dressnoscale/256/train/plugins/profile/2023_04_30_13_14_05Dumped tool data for xplane.pb to /Users/miguelnavaharris/New_Benchmarks/Prediction_accuracy/M1/Rescaled_correctly/PiNet_20_epochs_256_dressnoscale/256/train/plugins/profile/2023_04_30_13_14_05/ch-gouldmac7.ch.ic.ac.uk.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /Users/miguelnavaharris/New_Benchmarks/Prediction_accuracy/M1/Rescaled_correctly/PiNet_20_epochs_256_dressnoscale/256/train/plugins/profile/2023_04_30_13_14_05/ch-gouldmac7.ch.ic.ac.uk.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /Users/miguelnavaharris/New_Benchmarks/Prediction_accuracy/M1/Rescaled_correctly/PiNet_20_epochs_256_dressnoscale/256/train/plugins/profile/2023_04_30_13_14_05/ch-gouldmac7.ch.ic.ac.uk.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /Users/miguelnavaharris/New_Benchmarks/Prediction_accuracy/M1/Rescaled_correctly/PiNet_20_epochs_256_dressnoscale/256/train/plugins/profile/2023_04_30_13_14_05/ch-gouldmac7.ch.ic.ac.uk.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /Users/miguelnavaharris/New_Benchmarks/Prediction_accuracy/M1/Rescaled_correctly/PiNet_20_epochs_256_dressnoscale/256/train/plugins/profile/2023_04_30_13_14_05/ch-gouldmac7.ch.ic.ac.uk.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    419/Unknown - 380s 902ms/step - loss: 28.1270 - mean_absolute_error: 1.0892 - mean_squared_error: 28.0863Shape mismatch in elems: Tensor(\"pi_net/preprocess_layer/cond/Shape:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 13:20:22.881410: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419/419 [==============================] - 430s 1s/step - loss: 28.1270 - mean_absolute_error: 1.0892 - mean_squared_error: 28.0863 - val_loss: 0.1818 - val_mean_absolute_error: 0.3677 - val_mean_squared_error: 0.1818\n",
      "Epoch 2/20\n",
      "419/419 [==============================] - 680s 2s/step - loss: 0.1119 - mean_absolute_error: 0.2752 - mean_squared_error: 0.1118 - val_loss: 0.0050 - val_mean_absolute_error: 0.0617 - val_mean_squared_error: 0.0050\n",
      "Epoch 3/20\n",
      "419/419 [==============================] - 950s 2s/step - loss: 0.0134 - mean_absolute_error: 0.1008 - mean_squared_error: 0.0134 - val_loss: 0.0290 - val_mean_absolute_error: 0.1621 - val_mean_squared_error: 0.0290\n",
      "Epoch 4/20\n",
      "419/419 [==============================] - 1227s 3s/step - loss: 0.0321 - mean_absolute_error: 0.1496 - mean_squared_error: 0.0321 - val_loss: 0.0066 - val_mean_absolute_error: 0.0659 - val_mean_squared_error: 0.0066\n",
      "Epoch 5/20\n",
      "419/419 [==============================] - 1684s 4s/step - loss: 0.0089 - mean_absolute_error: 0.0783 - mean_squared_error: 0.0089 - val_loss: 0.0079 - val_mean_absolute_error: 0.0840 - val_mean_squared_error: 0.0079\n",
      "Epoch 6/20\n",
      "419/419 [==============================] - 1895s 5s/step - loss: 0.0051 - mean_absolute_error: 0.0638 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_absolute_error: 0.0629 - val_mean_squared_error: 0.0049\n",
      "Epoch 7/20\n",
      "419/419 [==============================] - 2121s 5s/step - loss: 0.0049 - mean_absolute_error: 0.0622 - mean_squared_error: 0.0049 - val_loss: 0.0052 - val_mean_absolute_error: 0.0640 - val_mean_squared_error: 0.0052\n",
      "Epoch 8/20\n",
      "419/419 [==============================] - 2309s 6s/step - loss: 0.0047 - mean_absolute_error: 0.0606 - mean_squared_error: 0.0047 - val_loss: 0.0037 - val_mean_absolute_error: 0.0541 - val_mean_squared_error: 0.0037\n",
      "Epoch 9/20\n",
      "419/419 [==============================] - 2483s 6s/step - loss: 0.0048 - mean_absolute_error: 0.0603 - mean_squared_error: 0.0048 - val_loss: 0.0033 - val_mean_absolute_error: 0.0515 - val_mean_squared_error: 0.0033\n",
      "Epoch 10/20\n",
      "419/419 [==============================] - 2906s 7s/step - loss: 0.0042 - mean_absolute_error: 0.0562 - mean_squared_error: 0.0042 - val_loss: 0.0032 - val_mean_absolute_error: 0.0515 - val_mean_squared_error: 0.0032\n",
      "Epoch 11/20\n",
      "382/419 [==========================>...] - ETA: 4:23 - loss: 0.0037 - mean_absolute_error: 0.0533 - mean_squared_error: 0.0037"
     ]
    }
   ],
   "source": [
    "network.fit(train_set, epochs=epochs,  validation_data=test_set, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = tf.keras.models.load_model('/Users/miguelnavaharris/New_Benchmarks/NVIDIA/PiNet_rescaled_correctly/157_epochs_dressnoscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 10:31:05.798541: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "all_pred_energies = []\n",
    "all_true_energies = []\n",
    "num_heavy_atoms = []\n",
    "molecule_masses = []\n",
    "for test_batch in test_set:\n",
    "    pred_energies = network(test_batch, training=False)\n",
    "    # pred_energies /= params['params']['e_scale']\n",
    "    if params['params']['e_dress']:\n",
    "        dress = atomic_dress(test_batch, params['params']['e_dress'], dtype=pred_energies.dtype)\n",
    "        pred_energies += dress\n",
    "\n",
    "    pred_energies = pred_energies.numpy()\n",
    "    atoms = test_batch[\"elems\"].numpy()\n",
    "    true_energies = test_batch[\"e_data\"].numpy()\n",
    "    molecule_indices = test_batch[\"ind_1\"].numpy()\n",
    "\n",
    "    all_pred_energies.extend(pred_energies.tolist())\n",
    "    all_true_energies.extend(true_energies.tolist())\n",
    "\n",
    "    unique_elements = np.unique(atoms)\n",
    "    element_masses = {int(elem_num): element(int(elem_num)).mass for elem_num in unique_elements}\n",
    "\n",
    "    for idx in range(true_energies.shape[0]):\n",
    "        molecule_atoms = atoms[molecule_indices[:, 0] == idx]\n",
    "        num_heavy = np.sum(molecule_atoms > 1)\n",
    "        num_heavy_atoms.append(num_heavy)\n",
    "\n",
    "        # Calculate molecule mass using Mendeleev\n",
    "        molecule_mass = sum(element_masses[int(elem_num)] for elem_num in molecule_atoms)\n",
    "        molecule_masses.append(molecule_mass)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'true_energy': all_true_energies,\n",
    "    'pred_energy': all_pred_energies,\n",
    "    'num_heavy_atoms': num_heavy_atoms,\n",
    "    'molecule_mass': molecule_masses,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.0029345662437935014\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataframe is named results\n",
    "results['abs_diff'] = (results['true_energy'] - results['pred_energy']).abs()\n",
    "mae = results['abs_diff'].mean()\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('/Users/miguelnavaharris/New_Benchmarks/NVIDIA/PiNet_rescaled_correctly/157_epochs_dressnoscale/predvstrue.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASE Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generator(molecule):\n",
    "        data = {'coord': molecule.positions,\n",
    "                'ind_1': np.zeros([len(molecule), 1]),\n",
    "                'elems': molecule.numbers}\n",
    "        yield data\n",
    "\n",
    "def predict_energy(molecule):\n",
    "        '''Takes an ASE Atoms object and outputs PiNet's energy prediction'''\n",
    "        dtype=tf.float32\n",
    "        dtypes = {'coord': dtype, 'elems': tf.int32, 'ind_1': tf.int32}\n",
    "        shapes = {'coord': [None, 3], 'elems': [None], 'ind_1': [None, 1]}\n",
    "\n",
    "        pred_dataset = tf.data.Dataset.from_generator(lambda:_generator(molecule), dtypes, shapes)\n",
    "\n",
    "        for molecule in pred_dataset:\n",
    "                molecule = network.preprocess(molecule)\n",
    "                pred = network(molecule, training=False)\n",
    "                ind = molecule['ind_1']\n",
    "                nbatch = tf.reduce_max(ind)+1\n",
    "                energy_prediction = tf.math.unsorted_segment_sum(pred, ind[:, 0], nbatch)\n",
    "                energy_prediction = energy_prediction / params['params']['e_scale']\n",
    "                if params['params']['e_dress']:\n",
    "                        energy_prediction += atomic_dress(molecule, params['params']['e_dress'], dtype=energy_prediction.dtype)\n",
    "                energy_prediction_numpy = energy_prediction.numpy()[0]\n",
    "        return energy_prediction_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-79.78593"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_energy(g2['C2H6'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4025a0c18342a57b4a17c482f921a5b0f0c41971fda061095662d1f6a4a25c7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('pinn2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
