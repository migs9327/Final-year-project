{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from spektral.data import DisjointLoader\n",
    "from spektral.datasets import QM9\n",
    "from spektral.layers import ECCConv, GlobalSumPool\n",
    "import time\n",
    "from datetime import datetime\n",
    "import psutil\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from mendeleev import element\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to disable GPU\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "tf.config.set_visible_devices(physical_devices[0], 'CPU')\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Config (learning rate decay)\n",
    "################################################################################\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=1e-3,\n",
    "            decay_steps=10000,\n",
    "            decay_rate=0.994)\n",
    "# learning_rate = 1e-3\n",
    "epochs = 1 # Number of training epochs\n",
    "batch_size = 256  # Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading QM9 dataset.\n",
      "Reading SDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 133885/133885 [01:03<00:00, 2093.75it/s]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Load data\n",
    "################################################################################\n",
    "dataset = QM9(amount=None)  # Set amount=None to train on whole dataset\n",
    "\n",
    "# Set labels to U0\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i].y = dataset[i].y[10]\n",
    "\n",
    "# Parameters\n",
    "F = dataset.n_node_features  # Dimension of node features\n",
    "S = dataset.n_edge_features  # Dimension of edge features\n",
    "n_out = dataset.n_labels  # Dimension of the target\n",
    "\n",
    "# Train/test split\n",
    "idxs = np.random.permutation(len(dataset))\n",
    "split = int(0.8 * len(dataset))\n",
    "idx_tr, idx_te = np.split(idxs, [split])\n",
    "dataset_tr, dataset_te = dataset[idx_tr], dataset[idx_te]\n",
    "\n",
    "loader_tr = DisjointLoader(dataset_tr, batch_size=batch_size, epochs=epochs)\n",
    "loader_te = DisjointLoader(dataset_te, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "num_molecules_tr = loader_tr.steps_per_epoch * batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Build model\n",
    "################################################################################\n",
    "class Net(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = ECCConv(32, activation=\"relu\")\n",
    "        self.conv2 = ECCConv(32, activation=\"relu\")\n",
    "        self.global_pool = GlobalSumPool()\n",
    "        self.dense = Dense(n_out)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a, e, i = inputs\n",
    "        x = self.conv1([x, a, e])\n",
    "        x = self.conv2([x, a, e])\n",
    "        output = self.global_pool([x, i])\n",
    "        output = self.dense(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "model = Net()\n",
    "optimizer = Adam(lr_schedule)\n",
    "loss_fn = MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomEarlyStopping(EarlyStopping):\n",
    "#     def __init__(self, patience=100, **kwargs):\n",
    "#         super().__init__(patience=patience, **kwargs)\n",
    "#         self.val_losses = []\n",
    "#         self.best = float('inf') if self.monitor_op == np.less else -float('inf')\n",
    "\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         val_loss = logs.get(\"val_loss\")\n",
    "#         self.val_losses.append(val_loss)\n",
    "#         super().on_epoch_end(epoch, logs)\n",
    "\n",
    "#         if self.wait >= self.patience:\n",
    "#             if self.stopped_epoch > 0 and self.restore_best_weights:\n",
    "#                 self.model.set_weights(self.best_weights)\n",
    "\n",
    "#             self.model.stop_training = True\n",
    "#             print(f\"Early stopping triggered. No improvement in validation loss for the past {self.patience} epochs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_metric = tf.keras.metrics.MeanSquaredError()\n",
    "train_mae_metric = tf.keras.metrics.MeanAbsoluteError()\n",
    "train_rmse_metric = tf.keras.metrics.RootMeanSquaredError()\n",
    "val_loss_metric = tf.keras.metrics.MeanSquaredError()\n",
    "val_mae_metric = tf.keras.metrics.MeanAbsoluteError()\n",
    "val_rmse_metric = tf.keras.metrics.RootMeanSquaredError()\n",
    "train_log_dir = '/Users/miguelnavaharris/New_Benchmarks/Prediction_accuracy/M1/Spektral_predvstrue/' + str(batch_size) + '/train'\n",
    "test_log_dir = '/Users/miguelnavaharris/New_Benchmarks/Prediction_accuracy/M1/Spektral_predvstrue/' + str(batch_size) + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "# early_stopping = CustomEarlyStopping(patience=2, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current process\n",
    "current_process = psutil.Process(os.getpid())\n",
    "# early_stopping.set_model(model)\n",
    "\n",
    "@tf.function(input_signature=loader_tr.tf_signature(), experimental_relax_shapes=True)\n",
    "def train_step(inputs, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(target, predictions) + sum(model.losses)\n",
    "        train_mae_metric.update_state(target, predictions)\n",
    "        train_rmse_metric.update_state(target, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def train_and_evaluate():\n",
    "    step = loss = total_batches = 0\n",
    "    epoch = 1\n",
    "    val_losses = []\n",
    "    start_epoch_time = time.time()\n",
    "    print(f'Starting epoch {epoch}')\n",
    "    for batch in loader_tr:\n",
    "        step += 1\n",
    "        total_batches += 1\n",
    "        loss += train_step(*batch)\n",
    "\n",
    "\n",
    "        if total_batches % 20 == 0 and total_batches != 0:\n",
    "\n",
    "\n",
    "            # Get the memory information of the current process\n",
    "            process_memory_info = current_process.memory_info()\n",
    "            ram_usage = process_memory_info.rss / (1024 ** 2)  # Convert to MB\n",
    "            swap_info = psutil.swap_memory()\n",
    "            swap_usage = swap_info.used / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "            with train_summary_writer.as_default():\n",
    "                tf.summary.scalar('batch_Loss', (loss / step), step=total_batches)\n",
    "                tf.summary.scalar('batch_MAE', train_mae_metric.result(), step=total_batches)\n",
    "                tf.summary.scalar('batch_RMSE', train_rmse_metric.result(), step=total_batches)\n",
    "                tf.summary.scalar('RAM_usage_MB', ram_usage, step=total_batches)\n",
    "                tf.summary.scalar('Swap_usage_MB', swap_usage, step=total_batches)\n",
    "              \n",
    "\n",
    "\n",
    "        if step == loader_tr.steps_per_epoch:\n",
    "            step = 0\n",
    "            epoch_train_time = time.time() - start_epoch_time\n",
    "            molecules_per_second = num_molecules_tr / epoch_train_time\n",
    "            print(\"molecules per second:\", molecules_per_second)\n",
    "            print(\"Loss: {}\".format(loss / loader_tr.steps_per_epoch))\n",
    "            print(f\"MAE: {float(train_mae_metric.result())}\")\n",
    "            print(f\"RMSE: {float(train_rmse_metric.result())}\")\n",
    "            with train_summary_writer.as_default():\n",
    "                tf.summary.scalar(f'epoch_Loss', (loss / loader_tr.steps_per_epoch), step=total_batches)\n",
    "                tf.summary.scalar(f'epoch_MAE', train_mae_metric.result(), step=total_batches)\n",
    "                tf.summary.scalar(f'epoch_RMSE', train_rmse_metric.result(), step=total_batches)\n",
    "                tf.summary.scalar(f'epoch_moleculespersec', molecules_per_second, step=total_batches)\n",
    "\n",
    "            train_mae_metric.reset_states()\n",
    "            train_rmse_metric.reset_states()\n",
    "            loss = 0\n",
    "\n",
    "            ################################################################################\n",
    "            # Evaluate model\n",
    "            ################################################################################\n",
    "            print(\"Testing model\")\n",
    "            val_step = val_loss = 0\n",
    "            for batch in loader_te:\n",
    "                val_step += 1\n",
    "                inputs, target = batch\n",
    "                predictions = model(inputs, training=False)\n",
    "                val_loss += loss_fn(target, predictions)\n",
    "\n",
    "                val_mae_metric.update_state(target, predictions)\n",
    "                val_rmse_metric.update_state(target, predictions)\n",
    "            \n",
    "                if val_step == loader_te.steps_per_epoch:\n",
    "                    val_step = 0\n",
    "                    val_loss /= loader_te.steps_per_epoch\n",
    "                    val_losses.append(val_loss)\n",
    "                    print(\"Validation loss: {}\".format(val_loss))\n",
    "                    print('Validation MAE:', float(val_mae_metric.result()))\n",
    "                    print('Validation RMSE:', float(val_rmse_metric.result()))\n",
    "                    with test_summary_writer.as_default():\n",
    "                        tf.summary.scalar('epoch_validation_Loss', val_loss, step=total_batches)\n",
    "                        tf.summary.scalar('epoch_validation_MAE', val_mae_metric.result(), step=total_batches)\n",
    "                        tf.summary.scalar('epoch_validation_RMSE', val_rmse_metric.result(), step=total_batches)\n",
    "            \n",
    "                        \n",
    "                    # logs = {\"val_loss\": val_loss, \"val_mae\": val_mae_metric.result()}\n",
    "                    # early_stopping.on_epoch_end(epoch - 1, logs)\n",
    "                    # if early_stopping.restore_best_weights:\n",
    "                    #     model.set_weights(early_stopping.best_weights)\n",
    "                    # if model.stop_training:\n",
    "                    #     return f\"Early stopping triggered. Training stopped at epoch {epoch}\"\n",
    "\n",
    "                    val_loss = 0\n",
    "                    val_mae_metric.reset_states()\n",
    "                    val_rmse_metric.reset_states()\n",
    "                    break\n",
    "\n",
    "            epoch += 1\n",
    "            if epoch <= epochs:\n",
    "                print(f'Starting epoch {epoch}')\n",
    "            start_epoch_time = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelnavaharris/spektral/spektral/data/utils.py:221: UserWarning: you are shuffling a 'QM9' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n",
      "/Users/miguelnavaharris/miniforge3/envs/spektraltf2.8/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:371: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
      "  return py_builtins.overload_of(f)(*args)\n",
      "2023-04-15 15:18:28.659200: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "molecules per second: 6909.385929008912\n",
      "Loss: 61708.85546875\n",
      "MAE: 220.37619018554688\n",
      "RMSE: 249.21556091308594\n",
      "Testing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelnavaharris/spektral/spektral/layers/convolutional/conv.py:93: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 11796.859375\n",
      "Validation MAE: 85.43062591552734\n",
      "Validation RMSE: 108.90721893310547\n",
      "Starting epoch 2\n",
      "molecules per second: 10030.991253729051\n",
      "Loss: 8621.796875\n",
      "MAE: 74.0617446899414\n",
      "RMSE: 92.91338348388672\n",
      "Testing model\n",
      "Validation loss: 6818.890625\n",
      "Validation MAE: 66.14544677734375\n",
      "Validation RMSE: 82.68148040771484\n",
      "Starting epoch 3\n",
      "molecules per second: 10136.127091822469\n",
      "Loss: 5525.3466796875\n",
      "MAE: 59.38648986816406\n",
      "RMSE: 74.4217300415039\n",
      "Testing model\n",
      "Validation loss: 4398.1728515625\n",
      "Validation MAE: 52.76784133911133\n",
      "Validation RMSE: 66.37173461914062\n",
      "Starting epoch 4\n",
      "molecules per second: 10112.904642527019\n",
      "Loss: 3519.953857421875\n",
      "MAE: 47.2893180847168\n",
      "RMSE: 59.39862060546875\n",
      "Testing model\n",
      "Validation loss: 2837.042724609375\n",
      "Validation MAE: 41.620384216308594\n",
      "Validation RMSE: 53.25392150878906\n",
      "Starting epoch 5\n",
      "molecules per second: 10108.075047439223\n",
      "Loss: 2236.09912109375\n",
      "MAE: 37.57269287109375\n",
      "RMSE: 47.34202194213867\n",
      "Testing model\n",
      "Validation loss: 1824.600341796875\n",
      "Validation MAE: 32.908782958984375\n",
      "Validation RMSE: 42.657901763916016\n",
      "Starting epoch 6\n",
      "molecules per second: 10031.203965993484\n",
      "Loss: 1406.52392578125\n",
      "MAE: 29.499807357788086\n",
      "RMSE: 37.47207260131836\n",
      "Testing model\n",
      "Validation loss: 1151.4061279296875\n",
      "Validation MAE: 25.755905151367188\n",
      "Validation RMSE: 33.96710968017578\n",
      "Starting epoch 7\n",
      "molecules per second: 9951.25488778646\n",
      "Loss: 878.5805053710938\n",
      "MAE: 22.968053817749023\n",
      "RMSE: 29.651906967163086\n",
      "Testing model\n",
      "Validation loss: 748.8338623046875\n",
      "Validation MAE: 20.15334129333496\n",
      "Validation RMSE: 27.402097702026367\n",
      "Starting epoch 8\n",
      "molecules per second: 9947.840750395366\n",
      "Loss: 580.1031494140625\n",
      "MAE: 18.299898147583008\n",
      "RMSE: 24.106721878051758\n",
      "Testing model\n",
      "Validation loss: 540.8975830078125\n",
      "Validation MAE: 16.6271915435791\n",
      "Validation RMSE: 23.214818954467773\n",
      "Starting epoch 9\n",
      "molecules per second: 8934.076347387241\n",
      "Loss: 434.39141845703125\n",
      "MAE: 15.589035034179688\n",
      "RMSE: 20.85348892211914\n",
      "Testing model\n",
      "Validation loss: 432.1771240234375\n",
      "Validation MAE: 14.714324951171875\n",
      "Validation RMSE: 20.82115364074707\n",
      "Starting epoch 10\n",
      "molecules per second: 9915.410268380834\n",
      "Loss: 351.812255859375\n",
      "MAE: 13.855521202087402\n",
      "RMSE: 18.771421432495117\n",
      "Testing model\n",
      "Validation loss: 360.01287841796875\n",
      "Validation MAE: 13.255744934082031\n",
      "Validation RMSE: 19.010360717773438\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/Users/miguelnavaharris/New_Benchmarks/NVIDIA/Spektral/14_epochs/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelnavaharris/spektral/spektral/data/utils.py:221: UserWarning: you are shuffling a 'QM9' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    }
   ],
   "source": [
    "def convert_to_elem_nums(atomsonehot):\n",
    "    elem_nums = [1, 6, 7, 8, 9]\n",
    "    elems = []\n",
    "    for i in range(len(atomsonehot)):\n",
    "        elems.append(elem_nums[np.nonzero(atomsonehot[:,:5][i])[0][0]])\n",
    "    return np.array(elems)\n",
    "\n",
    "loader_te = DisjointLoader(dataset_te, batch_size=batch_size, epochs=epochs)\n",
    "all_pred_energies = []\n",
    "all_true_energies = []\n",
    "num_heavy_atoms = []\n",
    "molecule_masses = []\n",
    "for batch in loader_te:\n",
    "    inputs, target = batch\n",
    "    predictions = model(inputs, training=False)\n",
    "    predictions = predictions.numpy()\n",
    "    all_pred_energies.extend(predictions[:,0].tolist())\n",
    "    all_true_energies.extend(target[:,0].tolist())\n",
    "    x, a, e, i = inputs\n",
    "    atomsonehot = x\n",
    "    elems = convert_to_elem_nums(atomsonehot)\n",
    "    molecule_indices = i\n",
    "\n",
    "    unique_elements = np.unique(elems)\n",
    "    element_masses = {int(elem_num): element(int(elem_num)).mass for elem_num in unique_elements}\n",
    "\n",
    "    for idx in range(len(target)):\n",
    "        molecule_atoms = elems[molecule_indices == idx]\n",
    "        num_heavy = np.sum(molecule_atoms > 1)\n",
    "        num_heavy_atoms.append(num_heavy)\n",
    "\n",
    "        molecule_mass = sum(element_masses[int(elem_num)] for elem_num in molecule_atoms)\n",
    "        molecule_masses.append(molecule_mass)\n",
    "        \n",
    "results = pd.DataFrame({\n",
    "    'true_energy': all_pred_energies,\n",
    "    'pred_energy': all_true_energies,\n",
    "    'num_heavy_atoms': num_heavy_atoms,\n",
    "    'molecule_mass': molecule_masses,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('/Users/miguelnavaharris/New_Benchmarks/NVIDIA/Spektral/14_epochs/test/predvstrue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1.8714138595301442\n"
     ]
    }
   ],
   "source": [
    "mae = np.mean(np.abs(results['true_energy'] - results['pred_energy']))\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbcfeb10c3762152ef4adf22be737ebb1f6ca712e6f3cd49e8b350e004745349"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('spektral2.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
